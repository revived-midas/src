To train an AI chatbot with a custom knowledge base using the ChatGPT API, you can follow these general steps:

Prepare your training data: Collect a dataset of conversations related to the knowledge you want to include in your chatbot. This dataset should include questions and their corresponding answers. You may also want to include some additional context or metadata, such as the user's location, to help the chatbot provide more personalized responses.

Preprocess your data: Clean and preprocess your training data to remove any irrelevant or noisy information. This may include removing special characters or punctuation, tokenizing the text, and removing stop words.

Train your chatbot: Use the ChatGPT API to fine-tune the GPT model on your preprocessed dataset. You can also customize the model hyperparameters to achieve better performance.

Test your chatbot: Evaluate the performance of your chatbot by testing it with sample questions and evaluating the responses. You may also want to use some metrics such as precision, recall, and F1-score to measure the accuracy of your chatbot.

As for the type of database that is best for training an AI chatbot, it depends on the specific domain and use case. For example, if you're building a dental chatbot, you may want to use a database of dental textbooks, academic journals, and other authoritative sources as your knowledge base. The key is to ensure that the database is reliable, up-to-date, and relevant to the domain in which your chatbot operates. You may also want to consider using a combination of structured and unstructured data to ensure that your chatbot can handle a wide range of queries and provide accurate responses.